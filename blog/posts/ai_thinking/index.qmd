---
title: "Dear Claude: Are We Getting Too Close?"
# description: "Some ideas on why some domains will benefit more from general-purpose models than others"
image: ""
sidebar: false
categories:
  - llm
  - academia
  - society
date: "1/12/2025"
bibliography: references.bib
include-in-header:
  text: |
    <style>
    .cell-output-stdout {
      overflow-y: scroll;
      max-height: 400px;
    }
    </style>
---


Lately, I have been wondering a lot about what the biggest impact of generative models on science and society can be. 

While [I see many upsides](https://kjablonka.com/blog/posts/why_llm/), I am also very puzzled and concerned by things happening to myself and many around me. 

This week, the Atlantic ran an outstanding piece by Derek Thompson on [The anti-social century](https://www.theatlantic.com/magazine/archive/2025/02/american-loneliness-personality-politics/681091/), and last year, Kevin Roose [described how some people now run everything, every decision, every thought through Claude](https://www.nytimes.com/2024/12/13/technology/claude-ai-anthropic.html) and perhaps talk more to Claude to their friends. 

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">i&#39;m starting to see differences between those who have integrated claude deeply into their lives and those who haven&#39;t. its still too early for me to put words on it... i think the ones who have feel better supported? it&#39;s been ~universally healthy so far from what i can tell</p>&mdash; Nick (@nickcammarata) <a href="https://twitter.com/nickcammarata/status/1862000614508777779?ref_src=twsrc%5Etfw">November 28, 2024</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

I also talk to Claude a lot. I asked Claude to review this post critically. I ask it to do the same for most of my writing. 
Many of my friends and colleagues do the same. Basically, all of the students I work with do talk to Claude. However, I am nervous about how some of us use it. 

<blockquote class="bluesky-embed" data-bluesky-uri="at://did:plc:u3o6qejoryiezdwepzbl4hqm/app.bsky.feed.post/3lfiu7ewr6k23" data-bluesky-cid="bafyreie7pp4xrcaibuxgoshgdycd2ffzatqbqnezaplimji5g25hswicjy"><p lang="en">
I had big hopes for the application of AI to education. I saw it as one of the most important problems of our time. I did not expect there could be a possibility that AI would not only keep students ignorant, but in fact make them fundamentally incapable of learning anything</p>&mdash; François Chollet (<a href="https://bsky.app/profile/did:plc:u3o6qejoryiezdwepzbl4hqm?ref_src=embed">@fchollet.bsky.social</a>) <a href="https://bsky.app/profile/did:plc:u3o6qejoryiezdwepzbl4hqm/post/3lfiu7ewr6k23?ref_src=embed">Jan 12, 2025 at 12:26 AM</a></blockquote><script async src="https://embed.bsky.app/static/embed.js" charset="utf-8"></script>

We have a tool in our hands that could do so much good. We could provide everyone with a personal tutor. We could use the models to bounce off ideas, think more critically, find loopholes, and brainstorm new ideas. 

The challenge isn't just technological - it's deeply human: perhaps our human nature makes it too tempting to take shortcuts [@Easter2021-gx]. To just directly let Claude solve a coding or homework problem or to just let Claude be the best friend. 

This is worrying because, as the models continue to saturate all our benchmarks, [Very interestingly, in creating [our own benchmark for chemistry](https://arxiv.org/abs/2404.01475) our limiting factor was human ingenuity and knowledge in coming up with questions that are challenging enough for the models.]{.aside} [the marginal value of interesting, clear, and wise thought increases](https://fs.blog/why-write/). “Low hanging fruit” test solving and knowledge retrieval are being commoditized - but we still need people who can set the agenda and push thought beyond the current frontiers. 

Being able to do so requires a [broad foundation of mental models](https://paulgraham.com/know.html) and playful curiosity [@Feynman1985-gy]. 

To me, one of the big challenges is how we can ensure most people and our students use generative AI as cointelligence [@Mollick2024-kq; @Mollick_2024] and not as a replacement for their own thought. [As Ethan Mollick pointedly observed: Education is hard.](https://www.oneusefulthing.org/p/post-apocalyptic-education) Growth is hard - but this is the point of it. 

Perhaps we need to do a better job of showing [the value of going through the grind](https://paulgraham.com/hwh.html) and the fun it takes. [And that shortcuts make us miss most of the journey.](https://paulgraham.com/writes.html) Perhaps we need to emphasize process over outcomes and reward original thinking over execution.

Learning, thinking, and talking to others [@Yanai_2024] is where the real magic happens — most of my best projects emerged from seemingly random discussions about seemingly unrelated topics (which some of the new [secular monks](https://www.firstthings.com/article/2020/03/secular-monks) might see as a waste of time).

The shortcuts AI offers might save time, but they could cost us something far more valuable: our capacity for genuine intellectual and personal growth and connection.

![I am sure that some ask Claude for help in all situations of their life and there are situations like this out in the wild. Image generated with getimg.ai](claude_at_date.png)