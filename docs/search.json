[
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Kevin's Homepage",
    "section": "",
    "text": "I take great pleasure in teaching and mentoring. I gave a number of lectures and tutorials on data management and machine learning at EPFL and the MolSim winterschool. Starting from my undergrad at TU Munich, I have been a teaching assistant and mentoring students.\n\n\nOne of my favorite teaching experiences was developing what we call a â€œvirtual laboratory.â€\n\nFor more details, you can check out our paper in J. Chem. Educ.\n\n\n\nI have been lucky to introduce students to machine learning. For this, I have developed a series of lectures and a hands-on exercise, which you can find on GitHub. Usually, we also host a Kaggle competition as part of the hands-on exercise. You can find an example of the competition here. Typically, I like to add some live-coding examples to the lecture. You can find the notebooks for those examples on GitHub."
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Kevin's Homepage",
    "section": "",
    "text": "My current and past research focuses on data-driven material design as well as the capture of (experimental) data in a machine-actionable form â€” which is pivotal to power data-driven approaches.\nThe central theme of my research is that material design is a very complex, mulitscale process that often involves questions that are not easily answered by simulations. Machine learning can help to address these questions and thereby accelerate material design and discovery and enable the development of new materials and yield to new insights.\n\n\nFor an overview of this research, see our Chem. Rev. as well as our perspective in JACS.\n\n\n\n\n\n\n\n\nAn ecosystem for digital reticular chemistry.\n\n\n\n\nA key challenge in data-driven material design, in particular for reticular chemistry, has been the lack of a comprehensive and open-source ecosystem for machine learning on reticular materials. To address this, we have been developing an open-source ecosystem for digital reticular chemistry, called mofdscribe. This ecosystem provides tools that accompany practioners along the entire data-driven design workflow: from data to publication. For this toolbox, we also developed and generalized a range of featurizers, i.e., methods to convert crystal structures into fixed-length vectors, which can be used to train machine learning models. For multiple featurizers, we could show that the generalization greatly improves the performance of the models.\n\n\n\nAnother exciting aspect of this work is that we have shown that it is straightforward to do machine-learning on crystallographic data incorrectlyâ€”and that this can lead to very misleading results.\nYou can find more details in the paper and on the open source page.\n\n\n\nGiven the tools and datasets mofdscribe provides of this, we can now use machine learning tools to address challenging material design problems.\nOver the last years, we have been doing this from the atom scale up to the pilot plant scale:\n\nFor instance, we have developed a machine learning model that can predict the oxidation state of metal cations in MOFs. This is interesting because oxidation states are a key part of chemical reasoning (they are even part of the names of the chemicals) but not quantum-mechanical observable. Using a chemically informed model, we could vastly outperform the state-of-the-art and show that the model reasons about the oxidation state in a way that is consistent with chemical intuition. For more details, see the paper.\nBeyond this, we have also been using machine learning to predict the color (see paper) as well as gas adsorption properties (see paper) of MOFs.\nRecently, we have shown how we can use machine learning to forecast the amine emission from a carbon capture pilot plant that is fed using a slipstream from a real power plant (see paper).\n\n\n\n\nThe power of machine learning in material discovery is that it can help us build a map of the chemical space. Equipped with this map, we can explore the chemical space more efficiently.\n\nDoing this for the design of materials is, however, complicated by the fact that we need to optimize multiple properties at the same time. There are often trade-offs between the properties we want to optimize, i.e., we cannot find a single optimum spot on the map, and the best we can do is to find the set of the best compromises. To avoid introducing biases in this process, we have implemented a method that allows to identify this set of best compromises (the Pareto frontier) with high confidence. You can find more information about this in our paper and an open-source implementation on GitHub.\n\n\n\nFor machine learning to work, it is important to work on actionable representations that are predictive. I think thank foundation models can help us reveal some of the tacit knowledge of chemistry.\n\n\n\n\n\n\n\n\n\n\n\nA digital assistant for chemists.\n\n\n\n\nHow can we generate an effective assistant for chemists to answer questions such as â€œfind all MOFs that can be made in one step in a solvothermal synthesis in water?â€ To answer questions like these, we need data in a form that cannot only be read by a machine but also understood in order to perform actions.\n\n\n\nIn order to ensure that data is an afterthought in chemistry, I got involved in the development of an open-source ELN, the cheminfo ELN (which development is led by Luc Patiny, our perspective article gives a good overview of our vision for the development of this platform). In contrast to many other ELNs, machine-actionable data is at the core of the ELN. This enables us to perform various actions on the data directly in the browser.\n\n\n\n\n\n\n\n\nIn many cases, we can only make sense of experimental data if we compare it to theoretical predictions. For instance, isotherms measure how much gas a material can adsorb as a function of pressure. Clearly, it can adsorb more if there are defects, such as missing linkers, and less if it is incompletely activated. However, to make those statements, one needs to compare to the isotherm of the â€œidealâ€ material. This is something one can do with simulations.\n\n\n\n\n\n\n\nPredict or look up XRD patterns on the fly.\n\n\n\n\nTo make such comparisons routine â€” but also to create rich datasets with data from both simulations and experiments â€” we made it very easy to â€œrequestâ€ simulations from within the ELN, by linking it to simulation platforms such as AiiDAlab or web services.\n\n\n\n\n\n\n\n\n\n\n\n\nDigital supporting information. The data is machine actionable and alive.\n\n\n\n\nOnce data is stored in a digital and machine-actionable form, we can use it to create electronic supporting information documents with just one click. In the cheminfo ELN, we make this possible by allowing users to export all their data to Zenodo. There, the data is accessible in a machine-actionable form and can interactively be explored in the browser. You can find an example of such a supporting information document here."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kevin's Homepage",
    "section": "",
    "text": "I lead a research group (supported by the Carl-Zeiss foundation) at the newly established Helmholtz Institute for Polymers in Energy Applications of the University of Jena and the Helmholz Center in Berlin. Iâ€™m using computational tools and machine learning to capture the tacit dimension of chemistry. Iâ€™m also a contributor to the cheminfo electronic lab notebook (ELN) ecosystem and other open-source projects (see my GitHub)."
  },
  {
    "objectID": "index.html#get-in-touch",
    "href": "index.html#get-in-touch",
    "title": "Kevin's Homepage",
    "section": "ðŸ’¼ Get in Touch",
    "text": "ðŸ’¼ Get in Touch\nEmail me, or DM me on  or  if youâ€™d like to chat!\nI appreciate any kind of feedback. If you want to leave some, you can do so anonymously here.\nIf you are looking for a short bio or a headshot, you can find them here."
  },
  {
    "objectID": "index.html#feed",
    "href": "index.html#feed",
    "title": "Kevin's Homepage",
    "section": "ðŸ“® Feed",
    "text": "ðŸ“® Feed\nBelow you can find some of my notes.\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\n\n\n\n\n3/24/24\n\n\nThe â€˜researcherâ€™s stuffâ€™\n\n\n\n\n3/2/24\n\n\nLanguage I want to be more mindful of\n\n\n\n\n3/2/24\n\n\nMultiple instances learning\n\n\n\n\n2/23/24\n\n\nDeveloping an intuition for backpropagation\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "openings.html",
    "href": "openings.html",
    "title": "Kevin's Homepage",
    "section": "",
    "text": "See also the PDF version of this announcement.\n\n\n\n\n\n\nMultiple PhD and PostDoc Positions at a newly founded research group at the University of Jena (Germany), led by Kevin Maik Jablonka.\n\n\n\nWe are looking for highly motivated Ph.D.Â students and postdocs for projects at the intersection of machine learning and chemistry and material science (digital chemistry), with a focus on data-driven design of polymer materials for energy applications. We will have multiple fully funded positions starting in summer/fall 2023.\nTogether, we will create impactful methods for accelerated material discovery across scalesâ€”ultimately helping us identify materials that work in the real world while also increasing understanding of why those materials work.\n\n\n\n\n\nWe will build digital assistants for chemists.\n\n\n\n\nThe design and discovery of new molecules and materials is slow. A major reason for that is that our research approach often relies on trial-and-error and is bottlenecked by information transfer: We would greatly benefit from having all information as well as intuition of all chemists at our fingertips. Machine learning can help us democratize access to this expert knowledge and help us navigate high-dimensional design spaces. In our lab will develop data-driven strategies for designing materials that work in the real world around three main research pillars: 1) Novel inductive biases (including â€œsoftâ€ inductive biases via LLMs), 2) Human-in-the-loop active learning, and 3) Novel learning paradigms. We will develop robust open-source software and also contribute to international research data initiatives. The PostDoc position will have a focus on this research data management aspect and the use of novel tools (such as LLMs) in this context.\n\n\n\nWe will design digital tools for designing polymers.\n\n\nDue to their unique tunability (and the correspondingly large design space) and functionality, we will focus on polymers, where we will closely collaborate with world-leading experimental partners to validate our predictions and build novel modeling and data frameworks.\nFor more background on my thinking see this website and my publications, you can contact him me email or on Twitter.\n\n\n\n\nSome background in chemistry, Chemical Engineering, Computer Science, Mathematics, Physics, or related fields. \nMotivation for working on challenging projects, passion for scientific research, and thrive for excellence.\nStrong teamwork and communication skills.\nGrowth mindset and inclusive team culture.\nExcellent written and oral communication skills in English.\nIdeally, programming and machine learning experience (e.g., in Python, Julia).\n\nList not exhaustive, if you are interested and think you might fit, please reach out.For the Ph.D.Â positions a Masterâ€™s degree or a four- or five-year Bachelorâ€™s degree in Chemistry, Chemical Engineering, Computer Science, Mathematics, Physics, or related fields. Without Masterâ€™s degree we will need to ask for an exception that is typically granted.\nFor the PostDoc positions a Ph.D.Â is required for employment.\n\n\n\n\nBe part of the story from the beginning when we start up an ambitious research program on digitizing chemistry and materials science.\nBecome part of an international and interdisciplinary research group within a scientific network that offers research and infrastructure at the highest level.\nWe collaborate with world-leading experimental groups in Jena as well as the Helmholtz Center in Berlin that have access to unique high-throughput experimentation as well as characterization setups.\nParticipate in international and national conferences, summer schools, and workshops (we have allocated a significant amount of resources for travel).\nBesides excellent in-house computational infrastructure (you will have multiple A100 cards waiting for you), Kevin is co-leading the ChemNLP project, for which we have access to resources from Stability.ai\nBecome part of a research group that cares about your personal development: We will create tailored personal development plans, that we review every year.\nA family-friendly working environment with a variety of offers for families: University Family Office (JUniFamilie) and flexible childcare (JUniKinder). University health promotion and a wide range of university sports activities.\nAttractive fringe benefits, e.g., capital formation benefits (VL), Job Ticket (benefits for public transport), and an occupational pension (VBL)\n30 days of recreational leave in the calendar year plus one day off for Dec.Â 24 and Dec.Â 31 that should be taken without any guilt.\n\n\n\n\nIf you want to do a master thesis, internship or simply connect, please reach out, too.\n\nSubmit your application via this form\nSelected candidates will be invited first to a non-technical discussion and then in a second round of a technical interview (including a ~25 minutes presentation).\n\nCandidates with disabilities will be given preference in the case of equal qualifications and suitability.\nWe will provide support for visa applications and any other potential relocation issues.\nWe will also support fellowship applications if you would prefer joining the lab on your own funding. Reach out for more details on suitable fellowships.\n\n\n\n\n\n\nWe will be a group in which we all work and grow together - including our digital agents.\n\n\nAt the Friedrich Schiller University (FSU) people from a wide range of (cultural and academic) backgrounds study and work together. At FSU, and in particular in our group, we see diversity as a strength and key for our success. We rely on different ways of thinking to create the most impactful research. Our group will be a place in which everyoneâ€“irrespective of the background feels safe and will be successful.\n\n\n\n\nThe Friedrich Schiller University is a traditional university with a strong research profile rooted in Jena, at the heart of Germany. Since its foundation, it has been one of Germanyâ€™s most famous places to study, where outstanding academics like Goethe and Schiller left their marks. As a university covering all disciplines, it offers a wide range of subjects. Its research is focused on the areas Lightâ€”Lifeâ€”Liberty. It is closely networked with non-research institutions, research companies (links going back to Carl Zeiss, Otto Schott, and Ernst Abbe) and renowned cultural institutions. With around 18,000 students and more than 8,600 employees, the university plays a major role in shaping Jenaâ€™s character as a cosmopolitan and future-oriented city (of around ~100 000 inhabitants). In Switzerland, I learned to love spending time in nature. One reason I like Jena is that you can be out in Nature by just walking a few minutes starting at the city center.\nOverall, Germany is a beautiful and safe country with great work-life balance and life satisfaction.\nYou will receive a very competitive salary with which you will live comfortably and save money for leisure activities. Students need approximately 700 EUR monthly for rent, food, health insurance, books, and personal items.\n\n\n\n\n\n\nRenderings of the new building our lab will be located in (opening fall 2023)\n\n\nOur lab (CZS Research group â€œPolymers for energy applicationsâ€) will be located in the newly constructed Center of Energy and Environmental Chemistry Jena II at the Landgrafencampus (close to one of the best viewpoints of the city), where four new buildings with ca. 7500 mÂ² lab space have been built over the last 10 years.\nFrequently, start-companies involving Ph.D.Â students and Postdocs are created, and a new incubator for chemistry related start-ups is currently built next to the campus.\n\n\n\nOur group is supported by the Carl-Zeiss Stiftung, the Helmholtz-Center Berlin and integrated in multiple collaborative research centers."
  },
  {
    "objectID": "blog/posts/bad_language/index.html",
    "href": "blog/posts/bad_language/index.html",
    "title": "Language I want to be more mindful of",
    "section": "",
    "text": "While an idea meritocracy might be an ideal way to run science. Academia is not a meritocracy.  Even worse, some of the language we (including myself) use might make some with great ideas feel unsafe and not welcome.Some of the metascience works of Aaron Clauset give great evidence for that. For example, this talk."
  },
  {
    "objectID": "blog/posts/bad_language/index.html#junior-group-leader",
    "href": "blog/posts/bad_language/index.html#junior-group-leader",
    "title": "Language I want to be more mindful of",
    "section": "Junior group leader",
    "text": "Junior group leader\nIn some communities, the term â€œjunior group leaderâ€ is quite common. Why is this suboptimal? The term â€œjuniorâ€ might suggest to some colleagues or students that the group leader has significantly less expertise or authority compared to â€œseniorâ€ colleagues and reinforces hierarchical structures within academia.\nA simple title such as â€œResearch Group Leaderâ€ without the â€œjuniorâ€ prefix can emphasize the role rather than the perceived hierarchy or experience level.\nBefore: â€œWe need a junior group leader to handle the initial phase.â€\nAfter: â€œWeâ€™re looking for an independent research leader to spearhead the initial phase.â€\nThis is a special case of seniority and age being more important in some societies than skill and accomplishment."
  },
  {
    "objectID": "blog/posts/bad_language/index.html#gender",
    "href": "blog/posts/bad_language/index.html#gender",
    "title": "Language I want to be more mindful of",
    "section": "Gender",
    "text": "Gender\nGender is diverse and nothing we can assume based on names, roles, or societal expectations. If we can be more proactive in communicating in a way that makes people more respected, we can do so.\nBefore: â€œEach student must submit his or her proposal by next week.â€\nAfter: â€œAll students must submit their proposals by next week.â€\nIn academia we can also be more inclusive by being mindful of how we address people. Instead of using Mr or Ms we can simply address them using gender-neutral earned titles.\nBefore: â€œDear Ms.Â Curieâ€\nAfter: â€œDear Dr.Â Curieâ€"
  },
  {
    "objectID": "blog/posts/bad_language/index.html#speaking-of-students-as-commodities",
    "href": "blog/posts/bad_language/index.html#speaking-of-students-as-commodities",
    "title": "Language I want to be more mindful of",
    "section": "Speaking of students as commodities",
    "text": "Speaking of students as commodities\n\n\n\nCartoon illustrating the commoditization of students.\n\n\nAs team leader, one easily slips into language that strips students of their human nature and makes them seem like a commodity for the production of papers. However, it is important to realize that we all have been a â€œproductive studentâ€ (or a less productive one) at points of our career.\nBefore: â€œWe need to put more students on this to increase our output.â€\nAfter: â€œLetâ€™s involve more team members to bring diverse perspectives and enrich our project.â€"
  },
  {
    "objectID": "blog/posts/bad_language/index.html#authorship-lists",
    "href": "blog/posts/bad_language/index.html#authorship-lists",
    "title": "Language I want to be more mindful of",
    "section": "Authorship lists",
    "text": "Authorship lists\nAuthorship is still the currency of academia. We currently indicate the â€œrelevanceâ€ of each other by their position on the list of others on a paper. However, contributions are very diverse and cannot be easily rank-ordered (there are many dimensions and introducing a total order would require us to introduce some weighting of the different dimensions).\nBefore: Listing authors strictly by seniority, regardless of contributions.\nAfter: Using contributorship statements that detail each authorâ€™s role, such as â€œA.B. designed the study and wrote the manuscript. C.D. conducted the experiments and analyzed the data.â€"
  },
  {
    "objectID": "blog/posts/researchers_stuff/index.html",
    "href": "blog/posts/researchers_stuff/index.html",
    "title": "The â€˜researcherâ€™s stuffâ€™",
    "section": "",
    "text": "In the hope of trying to better understand the thing I pretend to do for a living, I have been reading Isabelle Stengerâ€™s â€œAnother Science is Possible: A Manifesto for Slow Scienceâ€. My goal is to better understand why I feel that science is seemingly less efficient and why academia is a, perhaps, an increasingly â€œspecialâ€ place to work in.\nEarly in the book, she compares the â€œright stuffâ€ NASA test pilots needed to have with what she calls the â€œresearcherâ€™s stuffâ€.\n\n\n\nDALL Eâ€™s illustration of the â€œright stuffâ€ and â€œresearcherâ€™s stuffâ€\n\n\nIn Tom Wolfeâ€™s book the â€œright stuffâ€ was the â€œstuffâ€ the NASA pilots who survived had â€” and those who died didnâ€™t have\n\nIn this fraternity, even though it was military, men were not rated by their outward rank as ensigns, lieutenants, commanders, or whatever. No, herein the world was divided into those who had it and those who did not. This quality, this it, was never named, however, nor was it talked about in any way.\n\nStenger rephrases this as\n\nIt is precisely this unacceptable degree of dependency that the expression hides: whatever flying coffin they were given to test, those who were killed didnâ€™t have the right stuff.\n\nand links this to working conditions in academia\n\nFar from being treated as a primary resource that is now under threat, young researchers of either gender, doctoral students or postdocs, have to accept the realities of onerous working conditions and fierce competition. They are supposed to grin and bear it: the great adventure of human curiosity presented to them as children is replaced by the theme of a vocation that demands body-and-soul commitment. And this is what we accuse todayâ€™s young people of no longer accepting: compliance with the sacrifices that service to science demands.\n\nWhile there is a lot to say about (working) conditions in academia and how the system in many parts failed to evolve, the link to â€œover objectivizationâ€, which is perhaps very natural to many scientists, was more interesting to me. In an attempt to increase transparency and objectivity, â€œobjective metricsâ€ are being used to quantify how much â€œresearcher stuffâ€ a researcher has. However, those metrics do, of course, not work for every type of science (Stengerâ€™s attempts to show that they stem from what she calls â€œfast sciencesâ€). More importantly, however, we know from works such as the one from Kenneth Stanley and Joel Lehman that â€œgreatness cannot be plannedâ€ as paths to great discoveries ofteen go via â€œstepping stonesâ€ we cannot anticipate and which optimization of â€œnaiiveâ€ metrics would us not lead to.\n\n\n\nThere is empirical research that some things can be found more easily when not looking for it. This could, for example, be seen in the PicBreeder experiment where participants were asked to â€œbreedâ€ images.\n\n\nFrom this point of view, viewing academia via the lense of the comic Company Hierarchy by Hugh MacLeod makes some sense. In many layers of academia we have the tendency to optimize for metrics (h index, citations, â€¦) which is in this perspective the definition of the â€œcluelessâ€. [Stenger also has an interesting tangent how this might be tight to current science education. In a Kuhnian perspective of paradigms and â€œnormal scienceâ€, we are not really taught to question different ways of thinking, but rather focus in methodological details. Questioning different schools of thinking is perhaps more natural to the social sciences.]{:.aside}\n\n\n\nHugh MacLeodâ€™s Company Hierarchy.\n\n\n\nThe Clueless cannot process anything that is not finite, countable and external. They can only process the legible.â€ Certainly this describes the behavior of faculty, literally counting lines on their CV, grubbing for citations, breathlessly calculating their h-index.\n\nTo help science, Stenger argues that scientists should start caring more about the broader relevance of their work and not forget, what relevance means in the end: Not bibliometric metrics but rather evaluation by the community\n\nâ€œif a scientific claim can be trusted as reliable, it is not because scientists are objective, but because the claim has been exposed to the demanding objections of competent colleagues concerned about its reliabilityâ€\n\nLatter might sometimes correlate with bibliometric metrics but will not always do so. Simply because we rely on many different things (software, databases, â€¦) that are created on very different timescales.\nTo me, Stenger really urges us to step out of the â€œivory towerâ€ and â€œappreciate the originality or the relevance of an idea but also pay attention to questions or possibilities that were not taken into account in its production, but that might become important in other circumstancesâ€. This is also very important when we think about all the ways technologies can be misused. Stepping out of the ivory tower and taking society serious, however, probably also has to prompt us to rethink working conditions in academia.\nIn any case, I am very happy to see that new forms of doing science are being explored, because academia certainly is not the only and best way to do science."
  },
  {
    "objectID": "blog/posts/mil/index.html",
    "href": "blog/posts/mil/index.html",
    "title": "Multiple instances learning",
    "section": "",
    "text": "Molecules or materials are dynamic. At realistic temperatures, there will always be an ensemble of different conformers. In addition, we typically do not deal with pure materials but more commonly with blends for which the exact structure is not known.\nMultiple instances learning (MIL) is a framework that allows us to make predictions for such systems. For example, by thinking of molecules as bags of conformers or materials as bags of components of a blend.\nOften, practioners already use without explicitly naming it. An overview over applications in chemistry can be found in Zankov et al."
  },
  {
    "objectID": "blog/posts/mil/index.html#the-idea-behind-multiple-instances-learning",
    "href": "blog/posts/mil/index.html#the-idea-behind-multiple-instances-learning",
    "title": "Multiple instances learning",
    "section": "The idea behind multiple instances learning",
    "text": "The idea behind multiple instances learning\nAt its core, MIL is a variant of supervised learning that handles data grouped into bags, each containing multiple instances. In the context of chemical prediction, a â€œbagâ€ might represent a single chemical compound, and the â€œinstancesâ€ within could be different conformations, representations, or features of that compound. The distinctive aspect of MIL is that it assigns labels to bags, not to the individual instances they contain, making it particularly suited to scenarios where precise instance-level labels are hard to obtain or define.\nIt was formalized 1997 by a team around Thomas G. Dietterich with the goal of better drug-activity predictions.\n\n\n\nOverview of multiple instances learning. A bag (e.g.Â molecule) consists of multiple instances (e.g.Â conformers or tautomers). The goal is to make predictions for each bag."
  },
  {
    "objectID": "blog/posts/mil/index.html#approaches-to-mil",
    "href": "blog/posts/mil/index.html#approaches-to-mil",
    "title": "Multiple instances learning",
    "section": "Approaches to MIL",
    "text": "Approaches to MIL\nThere are different ways to perform MIL: At the instance-level or the bag-level\n\nInstance-level MIL\nThe perhaps conceptually simplest way to perform MIL is to make a prediction for each instance and then aggregate the predictions.\n\n\n\nOne approach to MIL is to make a prediction for each instance and to then aggregate those predictions.\n\n\nConceptually, this is quite similar to Behler-Parinello Neural Networks. Here, we decompose a target, such as the energy, into atomic contributions and then make predictions for atomic energies and then add those up.\n\n\n\nBehler-Parinello style models can be thought of instance-level MIL. We predict energies for each atom (instance) and then sum them up (aggregation) to obtain energies for the entire molecule (bag).\n\n\n\n\nBag-level MIL\nAlternatively, one might obtain a representation for each instance and then make predictions based on aggregated representations. Note that this is not different from what we typically do in a graph-neural network: We obtain a representation for each atom using, for example, graph convolutions, then aggregate those (e.g.Â by taking the mean) abnd then perform the prediction over the full molecule (the bag). Also the fingerprint averaging methods for copolymers or polymer blends proposed by Shukla et al. can be seen as special case of MIL.\n\n\n\nOne can perform MIL by using representations for each instance in a learning algorithm. The simplest approach might be to average representations and to then feed them into a feedforward neural network.\n\n\nIf we use a more learnable pooling mechanism (e.g.Â attention-based), we can also attempt to find out what the most important instances are. This is known as key-instance detection.\n\n\n\nAttention weighted aggregation might be used to identify key instances by identifying the largest attention weights\n\n\n\nSpecialized algorithms\n\nSet comparisons based\nSolving the MIL problem boils down to comparing sets. And there are various similarity measures for comparing set, which can then be implemented in distance-based algorithms such as SVM or kNN.\nA common metric is the Haussdorff distance. In this metric\n\\[\nd_{\\text {Hausdorff }}\\left(B_1, B_2\\right)=\\max \\left(\\operatorname {max } _ { b _ { i } \\in B _ { 1 } } \\left(\\min _{b_j \\in B_2}\\left(d\\left(b_i, b_j\\right)\\right), \\max _{b_i \\in B_2}\\left(\\min _{b_j \\in B_1}\\left(d\\left(b_i, b_j\\right)\\right)\\right)\\right.\\right.\n\\] where \\(d\\) is a distancve over the feature space of an instance \\(b\\) in a bag \\(B\\). Essentially, the Haussdorff distance is the distance of the point from one set that is furthest away from any point in the other set, considering both directions. This ensures that the Hausdorff Distance captures the worst-case scenario â€” the greatest of all the distances from a point in one set to the closest point in the other set.\n\n\n\nDiettrichâ€™s original algorithm: Axis Parallel Rectangles (APRS)\nThe idea is to learn a â€œconceptâ€ in feature space as axis-parallel rectangle $$$ in which there is - at least one instance from each positive example - exclude all instances from negative examples\nthe prediction is then positive if a new \\(x\\) is in the rectangle\n\\[\nf(x, R) = \\begin{cases}\n1 & x \\in R \\\\\n0 & \\text{else}\n\\end{cases}\n\\]\n\n\n\nIllustration of the axis-parallel rectangle approach. The filled shapes represent instances, the grey ellipses bags. The organe rectangle is the APR. Blue indicates negative instances, red ones postive ones. Each bag with at least one positive instance is labled as positive.\n\n\nIn the original article there are different algorithms for growing those rectangles. One rough implementation might look as follows:\n\nInitialization: Choose a seed positive instance to start constructing the APR.\nGrow APR: find the smallest APR that covers at least one instance of every positive molecule (i.e.Â bag). One can implement it greedly to add until there is at least one instance from every positive molecule. For addition, we choose the molecule that would lead to the smallest growth of the APR. This is run over a set of possible features.\nSelect Discriminating Features\n\nEvaluate each feature for its ability to exclude negative instances while including positive ones.\nSelect features that provide the best discrimination between positive and negative instances.\n\nExpand APR: The APR with the steps above is often too tight: â€œIt is typically so tight that it excludes most positive instances in the test setâ€. Those, one can\n\nApply kernel density estimation on each selected feature to determine the optimal expansion of the APR bounds.\nAdjust bounds to ensure a high probability of covering new positive instances and excluding negatives.\n\nIterate: Alternate between selecting discriminating features and expanding the APR until the process converges on a stable set of features and APR bounds."
  },
  {
    "objectID": "blog/posts/mil/index.html#references",
    "href": "blog/posts/mil/index.html#references",
    "title": "Multiple instances learning",
    "section": "References",
    "text": "References\n\nLecture notes on MIL by SebastiÃ¡n Ventura\nLecture notes by the Database Systems Group at LMU"
  },
  {
    "objectID": "blog/posts/backprop/index.html",
    "href": "blog/posts/backprop/index.html",
    "title": "Developing an intuition for backpropagation",
    "section": "",
    "text": "When we build neural networks, we tune weights to ensure that the outputs are close to what we want them to be.\nThe power of deep learning is that having many layers of weights allows us to learn very complex functions (i.e.Â mappings from input to output).\nHere, we want to understand how to systematically tune the weights to achieve this.\n \n  \n    \n    Neural Network Visualization\n    \n    \n  \n  \n    \n    \n        \n    \n      Input:\n      \n    \n    \n      Weight 1-1:\n      \n    \n    \n      Weight 1-2:\n      \n    \n    \n      Weight 2-1:\n      \n    \n    \n      Weight 2-2:\n      \n    \n    \n      Target Output:\n      \n    \n    Loss: 0.0000\n    \n    \n    \n    \n    \n  \nWhen we think of the tiny neural network in the widget above one might think of many different ways for optimizing the weights (line strenghts) of this model.\n\n\nOne option you might try is to randomly try different weight values to then find one that minimizes the difference between ground truth and prediction (i.e., minimizes the loss). While we might be lucky for this toy example, we can imagine that it might take a long time until we guessed all the weights in a billion-parameter model (e.g.Â GPT-3) correctly.\nUsing a strategy like a grid search (in which you loop over a range of possible weight values for all weights) will also only work for small models (think of the \\(100^4\\) combinations you would have to just try of 100 trial values for 4 weights).\n\n\n\nWhen we think of our neural network, the loss forms a landscape, that can be very complex. In our simple example below, it looks as follows:\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef relu(x):\n    return np.maximum(0, x)\n\ndef linear(x):\n    return x\n\n\ndef forward_pass(inputs, weights1, weights2, record_activation=False):\n    hidden_layer_input = np.dot(inputs, weights1)\n    hidden_layer_output = relu(hidden_layer_input)\n    output_layer_input = np.dot(hidden_layer_output, weights2)\n    output = linear(output_layer_input)\n    if record_activation:\n        return output, hidden_layer_output\n    return output\n\ndef compute_mse_loss(predicted, target):\n    loss =  np.mean(np.square(predicted - target))\n    return loss\n\n# Simplify the scenario for clear visualization\n# Set the target output and input\ntarget = 1.9\ninput_val = 0.8  # A simple input value to keep the forward pass straightforward\n\n# Define a range for weight updates that centers around an expected minimum\nweight_range = 3.5  # Explore weights within [-2, 2] for both weights\nnum_steps = 100  # Increase the number of steps for finer resolution\nstep_size = weight_range / num_steps\n\nweight1_1_range = np.linspace(0, weight_range, 2 * num_steps + 1)  # Start from 0 to weight_range\nweight2_1_range = np.linspace(-weight_range, weight_range, 2 * num_steps + 1)  # Keep full range for weight2_1\nweight1_1_vals, weight2_1_vals = np.meshgrid(weight1_1_range, weight2_1_range)\n\nfixed_weight1_2 = 1.2\nfixed_weight2_2 = 0.8\nlosses = np.zeros((len(weight1_1_range), len(weight2_1_range)))\n# Recalculate the losses with the updated range\nfor i in range(len(weight1_1_range)):\n    for j in range(len(weight2_1_range)):\n        current_weights1 = np.array([weight1_1_vals[i, j], fixed_weight1_2])\n        current_weights2 = np.array([weight2_1_vals[i, j], fixed_weight2_2])\n        output = forward_pass(np.array([[input_val]]), current_weights1.reshape(1, 2), current_weights2.reshape(2, 1))\n        losses[i, j] = compute_mse_loss(output, np.array([[target]]))\n\n# Create a 2D contour plot to visualize the loss landscape\nplt.figure()\nheatmap = plt.contourf(weight1_1_vals, weight2_1_vals, losses, levels=np.linspace(losses.min(), losses.max(), 50), cmap='viridis')\nplt.colorbar()\nplt.title('Loss Landscape')\nplt.xlabel('$w_1^1$ values')\nplt.ylabel('$w_2^1$ values')\nplt.show()\n\n\n\n\n\nTo create this plot, we keep two weights fixed, vary two others and then analyze how the loss looks like. We see that there is a clear structure that might remind us of a hilly landscape.\nWith the random search we have been randomly jumping around on this landscape. But seeing this image, we might also decide that we want to follow the path downhill; ultimately, our goal is to find the valley (the lowest loss). That is, the best value to try next should not be a random one but one downhill from where we are now.\nThis direction (â€œdownhillâ€) is the slope of our hilly landscape, i.e.Â the gradient.\n\\[\n\\frac{\\mathrm{d}f(x)}{\\mathrm{d}x} = \\lim_{h\\to0} \\frac{f(x+h) - f(x)}{h}\n\\]\nBased on the formula above, we might decide to compute a gradient numerically using finite differences.\nThe problem is that we need to perform many evaluations of the loss to make it work (one per weight, which can be a lot for current frontier models). In addition, we add up errors because \\(h\\) will be different from \\(0\\) (truncation error) and because be have to work with machine precision and hence add rounding errors.\n\n\n\n\n\n\nNote\n\n\n\nIf we compute numerical gradients, we have two main sources of error. One stems from the fact that \\(h\\) in the euqation above is not exactly 0. This is known as truncation error. On the other hand, the finite difference equation leads to numberical problems (rounding errors) as two almost identical numbers are substracted and then divided by a very small number.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the function and its exact derivative\ndef f(x):\n    return x**3\n\ndef df_exact(x):\n    return 3*x**2\n\n# Point at which to evaluate the derivative\nx = 1\n\n# Generate a range of h values (logarithmically spaced to cover small to larger values)\nh_values = np.logspace(-16, 0, 400)\nnumerical_derivatives = []\n\n# Calculate numerical derivative using forward difference for each h\nfor h in h_values:\n    numerical_derivative = (f(x+h) - f(x)) / h\n    numerical_derivatives.append(numerical_derivative)\n\n# Calculate exact derivative\nexact_derivative = df_exact(x)\n\n# Calculate errors\nerrors = np.abs(exact_derivative - np.array(numerical_derivatives))\n\n# Plotting\nplt.figure()\nplt.loglog(h_values, errors, label='Absolute Error', marker='o', linestyle='-', markersize=4, markevery=10)\nplt.xlabel('Step size $h$')\nplt.ylabel('Absolute Error')\nplt.title('Error in Numerical Derivative of $x^3$')\nplt.legend()\nplt.grid(True, which=\"both\", linestyle='--')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nObviously, we could save many evaluations when we could write down the derviates for a given functions. However, for our neural networks we cannot do this by hand.\nThe question is thus how we efficiently compute the gradient of function such as a neural network."
  },
  {
    "objectID": "blog/posts/backprop/index.html#evaluating-analytical-gradients-for-any-function-backpropagation",
    "href": "blog/posts/backprop/index.html#evaluating-analytical-gradients-for-any-function-backpropagation",
    "title": "Developing an intuition for backpropagation",
    "section": "Evaluating analytical gradients for any function: Backpropagation",
    "text": "Evaluating analytical gradients for any function: Backpropagation\n\nCalculus 101: Rules for computing derivatives\nLetâ€™s assume\n\\[\nf(x,y) = xy\n\\]\nthen the partial derivates are\n\\[\n\\frac{\\partial f}{\\partial x} = y \\quad \\frac{\\partial f}{\\partial y} = x\n\\]\nAn important rule for differentiation we will need to apply frequently, as it focusses on function composition, is the chain rule\n\\[\n(g(f(x)))^{\\prime}=(g \\circ f)^{\\prime}(x)=g^{\\prime}(f(x)) f^{\\prime}(x)\n\\]\nwith \\(g \\circ f\\) being function composition \\(x \\to f(x) \\to g(f(x))\\).\nIn the multivariate case, we would write\n\\[\n\\frac{\\mathrm{d}}{\\mathrm{d} t} f(x(t), y(t))=\\frac{\\partial f}{\\partial x} \\frac{\\mathrm{d} x}{\\mathrm{~d} t}+\\frac{\\partial f}{\\partial y} \\frac{\\mathrm{d} y}{\\mathrm{~d} t}.\n\\]\n\n\n\n\n\n\nIntuitive understanding of chain rule\n\n\n\nHow do you intuitively understand that? Letâ€™s borrow from George F. Simmons:\n\nIf a car travels twice as fast as a bicycle and the bicycle is four times as fast as a walking man, then the car travels 2 Ã— 4 = 8 times as fast as the man.\n\nWith\n\n\\(x\\) the position of the car\n\\(y\\) the position of the bicycle\n\\(z\\) the position of the walking man\n\nThe rate of change in relative positions is given by terms like \\(\\frac{\\mathrm{d}x}{\\mathrm{d}y}\\), which gives us the change in relative position of bicycle and car. It we now aim to compute the rate of change of relative position of car to the walking man, \\(\\frac{\\mathrm{d}x}{\\mathrm{d}z}\\), we find\n\\[\n\\frac{\\mathrm{d}x}{\\mathrm{d}x} = \\frac{\\mathrm{d}x}{\\mathrm{d}y} \\frac{\\mathrm{d}y}{\\mathrm{d}z} = \\underbrace{2}_{\\text{car twice as fast as bicycle}} \\cdot \\underbrace{4}_{\\text{bicycle is four times as fast as walking man}} = 8\n\\]\n\n\n\n\nComputing derivatives as in calculus 101\nIn neural networks, we nest functions. That is, will end up differentiating compound expression of the form\n\\[\n{\\displaystyle h(x)=f(g(x))}\n\\]\nFor instance, you might look at a simple regularized logistic regression:\n\\[\nL = \\frac{1}{2}\\left(\\sigma(wx +b) -t \\right)^2 + \\frac{\\lambda}{2} w^2,\n\\]\nwhere \\(\\sigma\\) is some activation function (e.g.Â the sigmoid).\nIf we now want to know what the influence of the weight \\(w\\) is, we can differentiate the loss with respect to \\(w\\):\n\\[\n\\begin{align}\n\\frac{\\partial L}{\\partial w} &= \\frac{\\partial}{\\partial w} \\left[\\frac{1}{2}\\left(\\sigma(wx +b) -t \\right)^2 + \\frac{\\lambda}{2} w^2 \\right] \\\\\n&= \\frac{1}{2}\\frac{\\partial}{\\partial w} \\left(\\sigma(wx +b) -t \\right)^2 + \\frac{\\lambda}{2}\\frac{\\partial}{\\partial w} w^2 \\\\\n&= \\left(\\sigma(wx+b) - t\\right)\\frac{\\partial}{\\partial w}\\left(\\sigma(wx+b)-t\\right) + \\lambda w \\\\\n&= \\left(\\sigma(wx+b) - t\\right)\\sigma'(wx +b)\\frac{\\partial}{\\partial w}(wx+b) + \\lambda w \\\\\n&= \\left(\\sigma(wx+b) - t\\right)\\sigma'(wx +b)x + \\lambda w\n\\end{align}\n\\]\nPuh! That was a lot of copying and pasting and quite error prone. And it might be quite costly to just directly evaluate such an expression (we might end up with an exponentially large expression, â€œexpression swellâ€).\nThere must be a better way.\n\n\nMaking it efficient with caching\nOne thing that we can observe is that we need to do the same computation several times. For instance, \\(wx +b\\) is evaluated two times. We code trade off space and time complexity by caching this using an intermediate variable.\nIf we do this systematically, we can very efficiently compute gradients â€“ in a form that is symmetric to the computation of the function itself (and those with basically the same cost).\n\nGeneral computation with intermediate values\nAs a simple example, letâ€™s start with\n\\[\nf(x,y,z) = (x+y)z\n\\]\nIt can be convienient to introduce the following intermediate variable\n\\[\np = (x + y)\n\\]\nWe can then write\n\\[\nf = pz\n\\]\nand also compute some partial derivatives\n\\[\n\\frac{\\partial f}{\\partial q} = z \\quad \\frac{\\partial f}{\\partial z} = q\n\\]\nand we also know how to differentiate \\(p\\) for \\(x\\) and \\(y\\):\n\\[\n\\frac{\\partial p}{\\partial x} = 1 \\quad \\frac{\\partial p}{\\partial y} =1.\n\\]\nUsing the chain rule we can combine those findings, as the chain rule states that we need to multiply the gradients to chain them:\n\\[\n\\frac{\\partial f(p,z)}{\\partial x} = \\frac{\\partial f(p, x)}{\\partial p}  \\frac{\\partial p(x,y)}{\\partial x}\n\\]\nThis typically means that two numbers are multiplied.\nIf we try it for the example above we can use the following code. Note how we cache intermediate results (i.e.Â trade off time- vs.Â space-complexity).\n\n# the inputs we will use \nx = -2\ny = 5\nz = -4\n\n# let's compute our intermediate terms\nt1 = x + y \nf = t1 * z\n\nNow, we can look at the derivatives we got above\n\ndt1dx = 1.\ndt1dy = 1.\n\ndfdt1 = z\ndfdz = t1\n\nNow, we can use the chain rule to combine them\n\ndfdx = dfdt1 * dt1dx\ndfdy = dfdt1 * dt1dy\n\nThe sensitivity to \\(x\\), \\(y\\), and \\(z\\) is hence\n\nprint(dfdz, dfdy, dfdz)\n\n3 -4.0 3\n\n\nBefore we move ahead, realize what we did:\nWe computed gradients by recursively applying the chain rule, starting at the end:\n\nour computation graph is x -> p -> f\nwe first compute df/dp, then dp/dx. Chaining them gives us df/dx = df/dp dp/dx\n\nWe can write this in a more general form as follows.\nIf we assume we have \\(N\\) intermediate variables \\(t_N\\), with \\(t_N\\) being our output \\(f\\), by definition we have\n\\[\n\\frac{\\mathrm{d}{f}}{\\mathrm{d}t_N} = 1\n\\]\nFor the other intermediate variables we have:\n\\[\n\\begin{align}\n\\frac{\\mathrm{d}f}{\\mathrm{d} t_{n-1}} &= \\frac{\\mathrm{d}f}{\\mathrm{d}f_{n}} \\frac{\\mathrm{d}f_{n}}{\\mathrm{d}t_{n-1}} \\\\\n\\frac{\\mathrm{d}f}{\\mathrm{d} t_{n-2}} &= \\frac{\\mathrm{d}f}{\\mathrm{d}f_{n}} \\frac{\\mathrm{d}f_{n}}{\\mathrm{d}t_{n-1}} \\frac{\\mathrm{d}f_{n-1}}{\\mathrm{d}t_{n-2}} \\\\\n\\frac{\\mathrm{d}f}{\\mathrm{d} t_{n-3}} &= \\frac{\\mathrm{d}f}{\\mathrm{d}f_{n}} \\frac{\\mathrm{d}f_{n}}{\\mathrm{d}t_{n-1}} \\frac{\\mathrm{d}f_{n-1}}{\\mathrm{d}t_{n-2}} \\frac{\\mathrm{d}f_{n-2}}{\\mathrm{d}t_{n-3}} \\\\\n\\frac{\\mathrm{d}f}{\\mathrm{d} t_i} &= \\frac{\\mathrm{d}f}{\\mathrm{d}f_{n}} \\frac{\\mathrm{d}f_{n}}{\\mathrm{d}t_{n-1}} \\frac{\\mathrm{d}f_{n-1}}{\\mathrm{d}t_{n-2}} \\ldots \\frac{\\mathrm{d}f_{i+1}}{\\mathrm{d}t_{i}}\n\\end{align}\n\\]\nNote that many of the terms we computed can be reused.\n\n\n\nApplication to neural networks\nNeural networks are more complicated circuits â€“ nested functions.\nLetâ€™s assume a very simply case\n\\[\ny=\\frac{1}{1+\\exp (-(wx+b))}.\n\\]\nWe can write it using the chaining of the following primitive operations (forming our computation graph).\n\\[\nt_1 = wx\n\\] \\[\nt_2 = t_1 + b\n\\]\n\\[\nt_3 = âˆ’t_2\n\\]\n\\[\nt_4 = \\exp(t_3)\n\\]\n\\[\nt_5 = 1 + t_4\n\\]\n\\[\nt_6 = 1/t_5\n\\]\n(this list of evaluations is sometimes called evaluation trace or Wengert list).\nAs we would like again get the derivative w.r.t to the output like the loss\n\\[\nL = (t_6-y)^2,\n\\]\nwhich we can write down with some more evaluations\n\\[\nt_7 = t_6-t\n\\]\n\\[\nt_8 = t_7^2.\n\\]\nWe call this evaluation the forward pass.\nThe beauty of backprop is that the computation for the derivative follows the same structure as the computation of the function itself (and, for example, is not drastically more complex as one might expect). To see this, we can try out:\n\\[\n\\begin{align}\n\\frac{\\partial t_8}{\\partial t_8} &= 1 \\\\\n\\frac{\\partial t_8}{\\partial t_7} &= 2 t_7 \\\\\n\\frac{\\partial t_7}{\\partial t_6} & = 1 \\\\\n\\frac{\\partial t_6}{\\partial t_5} &=  -1/t_5^2 \\\\\n\\frac{\\partial t_5}{\\partial t_4} &= 1\\\\\n\\frac{\\partial t_4}{\\partial t_3} &= \\exp(t_3) t_3 \\\\\n\\frac{\\partial t_3}{\\partial t_2} &= - 1\\\\\n\\frac{\\partial t_2}{\\partial t_1} &= 1 \\\\\n\\frac{\\partial t_1}{\\partial w} &= x\n\\end{align}\n\\]\nArmed with those partial derivatives, we can now multiply them to get the final goal â€“ the derivative of the loss w.r.t. the weight (\\(\\frac{\\partial L}{\\partial w}\\)).\n\\[\n\\begin{align}\n\\frac{\\partial t_8}{\\partial t_6} &= \\frac{\\partial t_8}{\\partial t_7} \\frac{\\partial t_7}{\\partial t_6} = 2 t_7 \\cdot 1 = 2(t_6 -y) \\\\\n\\frac{\\partial t_8}{\\partial t_5} &= \\frac{\\partial t_8}{\\partial t_6} \\frac{\\partial t_6}{\\partial t_5} = 2(t_6 -y) \\cdot  \\left(-\\frac{1}{t_5^2} \\right) =  -2/t_5^2 (t_6 -y) \\\\\n\\frac{\\partial t_8}{\\partial t_4} &= \\frac{\\partial t_8}{\\partial t_5} \\frac{\\partial t_5}{\\partial t_4} = -2/t_5^2 (t_6 -y) \\cdot 1 = -2/t_5^2 (t_6 -y) \\\\\n\\frac{\\partial t_8}{\\partial t_3} &= \\frac{\\partial t_8}{\\partial t_4} \\frac{\\partial t_4}{\\partial t_3} = -2/t_5^2 (t_6 -y) \\cdot \\exp(t_3) t_3 = -2/t_5^2 (t_6 -y) \\cdot \\exp(t_3) t_3 \\\\\n\\frac{\\partial t_8}{\\partial t_2} &= \\frac{\\partial t_8}{\\partial t_3} \\frac{\\partial t_3}{\\partial t_2} = -2/t_5^2 (t_6 -y) \\cdot \\exp(t_3) t_3 \\cdot -1 = 2/t_5^2 (t_6 -y) \\cdot \\exp(t_3) t_3 \\\\\n\\frac{\\partial t_8}{\\partial t_1} &= \\frac{\\partial t_8}{\\partial t_2} \\frac{\\partial t_2}{\\partial t_1} =  2/t_5^2 (t_6 -y) \\cdot \\exp(t_3) t_3 \\\\\n\\frac{\\partial t_8}{\\partial w} &= \\frac{\\partial t_8}{\\partial t_1} \\frac{\\partial t_1}{\\partial w} = 2/t_5^2 (t_6 -y) \\cdot \\exp(t_3) t_3 \\cdot x\n\\end{align}\n\\]\nIn practice, we would use autodifferentiation using a datastructure as follows to keep track of the computation graph.\n\n\nCode\n# code taken from https://github.com/karpathy/micrograd/blob/master/trace_graph.ipynb\nfrom graphviz import Digraph\n\ndef trace(root):\n    nodes, edges = set(), set()\n    def build(v):\n        if v not in nodes:\n            nodes.add(v)\n            for child in v._prev:\n                edges.add((child, v))\n                build(child)\n    build(root)\n    return nodes, edges\n\ndef draw_dot(root, format='svg', rankdir='LR'):\n    \"\"\"\n    format: png | svg | ...\n    rankdir: TB (top to bottom graph) | LR (left to right)\n    \"\"\"\n    assert rankdir in ['LR', 'TB']\n    nodes, edges = trace(root)\n    dot = Digraph(format=format, graph_attr={'rankdir': rankdir}) #, node_attr={'rankdir': 'TB'})\n    \n    for n in nodes:\n        dot.node(name=str(id(n)), label = \"{ data %.4f | grad %.4f }\" % (n.data, n.grad), shape='record')\n        if n._op:\n            dot.node(name=str(id(n)) + n._op, label=n._op)\n            dot.edge(str(id(n)) + n._op, str(id(n)))\n    \n    for n1, n2 in edges:\n        dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n    \n    return dot\n\n\n\n# taken from micrograd\nimport numpy as np\nclass Value:\n    \"\"\" stores a single scalar value and its gradient \"\"\"\n\n    def __init__(self, data, _children=(), _op=''):\n        self.data = data\n        self.grad = 0\n        # internal variables used for autograd graph construction\n        self._backward = lambda: None\n        self._prev = set(_children)\n        self._op = _op # the op that produced this node, for graphviz / debugging / etc\n\n    def __add__(self, other):\n        other = other if isinstance(other, Value) else Value(other)\n        out = Value(self.data + other.data, (self, other), '+')\n\n        # propagate the gradient on out to parents\n        # i.e. self and other \n        # since out = self + other, then d(out)/dself = 1 and d(out)/dother = 1\n        # so we can just add the gradient to both parents\n        def _backward():\n            self.grad = out.grad\n            other.grad = out.grad\n        out._backward = _backward\n\n        return out\n\n    def __mul__(self, other):\n        other = other if isinstance(other, Value) else Value(other)\n        out = Value(self.data * other.data, (self, other), '*')\n\n        def _backward():\n            self.grad = other.data * out.grad\n            other.grad = self.data * out.grad\n        out._backward = _backward\n\n        return out\n\n    def __pow__(self, other):\n        assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n        out = Value(self.data**other, (self,), f'**{other}')\n\n        def _backward():\n            self.grad = (other * self.data**(other-1)) * out.grad\n        out._backward = _backward\n\n        return out\n\n    def exp(self):\n        out = Value(np.exp(self.data), (self,), 'exp')\n\n        def _backward():\n            self.grad = np.exp(self.data) * out.grad\n        out._backward = _backward\n\n        return out\n\n    def __neg__(self): # -self\n        return self * -1\n\n    def __radd__(self, other): # other + self\n        return self + other\n\n    def __sub__(self, other): # self - other\n        return self + (-other)\n\n    def __rsub__(self, other): # other - self\n        return other + (-self)\n\n    def __rmul__(self, other): # other * self\n        return self * other\n\n    def __truediv__(self, other): # self / other\n        return self * other**-1\n\n    def __rtruediv__(self, other): # other / self\n        return other * self**-1\n\n    def __repr__(self):\n        return f\"Value(data={self.data}, grad={self.grad})\"\n\nWe can now write down our expression from before using the Value class\n\n# initialize some values\nw = Value(2.0)\nb = Value(0.0)\n\n# define the input\nx = Value(1.0)\ntarget = Value(10.0)\n\n# define the computation\nt1 = w * x\nt2 = t1 + b\nt3 = -1 * t2\nt4 = t3.exp()\nt5 = t4 + 1\nt6 = t5**(-1)\n\nt7 = t6 - target\nt8 = t7**2\n\ndraw_dot(t8)\n\n\n\n\nWe need to seed the gradient of the loss\n\nt8.grad = 1.0\n\nNow, we can perform the backward pass by calling the _backward function of the loss node, which will in turn call the _backward functions of all its parents, and so on, until the entire graph has been visited.\n\n# #| \nt8._backward()\nprint(t7.grad, t6.grad, t5.grad, t4.grad, t3.grad, w.grad, b.grad, x.grad)\n\n-18.238405844044234 0 0 0 0 0 0 0\n\n\n\n# #| \nt7._backward()\nprint(t7.grad, t6.grad, t5.grad, t4.grad, t3.grad, w.grad, b.grad, x.grad)\n\n-18.238405844044234 -18.238405844044234 0 0 0 0 0 0\n\n\n\n# #| \nt6._backward()\nprint(t7.grad, t6.grad, t5.grad, t4.grad, t3.grad, w.grad, b.grad, x.grad)\n\n-18.238405844044234 -18.238405844044234 14.149418952798422 0 0 0 0 0\n\n\n\n# #| \nt5._backward()  \nprint(t7.grad, t6.grad, t5.grad, t4.grad, t3.grad, w.grad, b.grad, x.grad)\n\n-18.238405844044234 -18.238405844044234 14.149418952798422 14.149418952798422 0 0 0 0\n\n\n\n# #| \nt4._backward()\nprint(t7.grad, t6.grad, t5.grad, t4.grad, t3.grad, w.grad, b.grad, x.grad)\n\n-18.238405844044234 -18.238405844044234 14.149418952798422 14.149418952798422 1.9149156216104704 0 0 0\n\n\n\n# #| \nt3._backward()\nprint(t7.grad, t6.grad, t5.grad, t4.grad, t3.grad, w.grad, b.grad, x.grad)\n\n-18.238405844044234 -18.238405844044234 14.149418952798422 14.149418952798422 1.9149156216104704 0 0 0\n\n\n\n# #| \nt2._backward()\nw._backward()\nprint(t7.grad, t6.grad, t5.grad, t4.grad, t3.grad, w.grad, b.grad, x.grad)\n\n-18.238405844044234 -18.238405844044234 14.149418952798422 14.149418952798422 1.9149156216104704 0 -1.9149156216104704 0\n\n\nTo avoid calling the backward function multiple times, we can implement a backprop function that traverses the graph in reverse topological order and calls the _backward function of each node only once.\nTopological sorting can be implemented using the following code\n\ntopo = []\nvisited = set()\ndef build_topo(v):\n    if v not in visited:\n        visited.add(v)\n        for child in v._prev:\n            build_topo(child)\n        topo.append(v)\n\n\n\n\n\n\n\nWhy does this sorting algorithm work?\n\n\n\n\nThe algorithm is a depth-first search (DFS)\nThe deepest nodes are added to the topo list first\nRecursiveness ensures that nodes another node depends on are added first (topo.append only happens after the recursive call)\n\nNote that this algorithm does not work for cyclic graphs.\n\n\nNow, we can simply write\n\n# #| \n# initialize some values\nw = Value(2.0)\nb = Value(0.0)\n\n# define the input\nx = Value(1.0)\ntarget = Value(10.0)\n\n# define the computation\nt1 = w * x\nt2 = t1 + b\nt3 = -1 * t2\nt4 = t3.exp()\nt5 = t4 + 1\nt6 = t5**(-1)\n\nt7 = t6 - target\nt8 = t7**2\n\nAnd now call the topological sorting and then _backward for all nodes\n\nt8.grad = 1.0\n\nbuild_topo(t8)\n\nfor v in reversed(topo):\n    v._backward()\n\nw.grad\n\n-1.9149156216104704\n\n\nNote that we had to reverse the topological ordering because the deepest dependent of t8 was first and we need to work backwards."
  },
  {
    "objectID": "blog/posts/backprop/index.html#lecture",
    "href": "blog/posts/backprop/index.html#lecture",
    "title": "Developing an intuition for backpropagation",
    "section": "Lecture",
    "text": "Lecture\nIf you prefer watching a short video over reading you can see me go through the gist of backprop in the following video."
  },
  {
    "objectID": "blog/posts/backprop/index.html#resources",
    "href": "blog/posts/backprop/index.html#resources",
    "title": "Developing an intuition for backpropagation",
    "section": "Resources",
    "text": "Resources\n\nAndrej Karpathy â€œHackerâ€™s guide to Neural Networksâ€ inspired the comparison between random search and gradient descent. The same ideas are used in the cs231n lecture notes since he taught this class. The chain rule example is taken from the c231n lecture notes\nAndrej Karparthy recorded a lecture in which he builds an autodiff system from scratch and it inspired many parts of the notebooks, some parts (the Value class) are taken from his lecture.\nDeisenroth et al.Â â€œMathematics of Machine Learningâ€ has a beautiful chapter about backprop and autodiff.\nMark Saroufim â€œAutomatic Differentiation Step by Stepâ€ has an intuitive explaination of dual numbers and has a good resource section, including \nAutomatic Differentiation in Machine Learning: a Survey is a great survey that clarifies many terms.\nMichael Nielsenâ€™s book highlights some of the â€œhiddenâ€ assumptions.\nBrandon Rohrer has a very intuitive of the chain rule in terms of the shower rate (similar to the bicycle/car/man example above).\nDeep Learning Systems Lecture at CMU has a detailed slides on the algorithmic details behind autodiff.\nDifferentiation for Hackers has nice Julia code that showcases what makes autodiff special (and different from symbolic and numeric differentiation).\nKyle Cranmer has a useful intro to autodiff. I took the sympy example from there."
  },
  {
    "objectID": "blog/posts/backprop/index.html#further-reading",
    "href": "blog/posts/backprop/index.html#further-reading",
    "title": "Developing an intuition for backpropagation",
    "section": "Further reading",
    "text": "Further reading\n\nWho â€œinventedâ€ backpropagation\nAs with many popular things, there is some debate on â€œwho was firstâ€. You can find some discussion on this here.\n\nâ€œOriginalâ€ Backprop Paper\nIn the context of training neural networks, backpropagation was popularized in a beatiful paper by David E. Rumelhart et al. It is beautiful and you should read it.\n\n\n\nBackpropagation and Lagrangian\nAs this blog post by Tim Viera and this paper by Yann LeCun show, the intermediate variables can be recovered by rephrasing the optimization as a constrained optimization using the Lagrangian framework.\n\n\nForward vs.Â reverse mode autodiff\nIf we have a computation graph as follows\nx -> a -> b -> y\nwe can compute the derivative of the output with respect to the input as\n\\[\n\\frac{\\mathrm{d}y}{\\mathrm{d}x} = \\frac{\\mathrm{d}y}{\\mathrm{d}b}\\frac{\\mathrm{d}b}{\\mathrm{d}a} \\frac{\\mathrm{d}a}{\\mathrm{d}x}\n\\]\nsince multiplication is associative, we can choose between computing\n\\[\n\\frac{\\mathrm{d}y}{\\mathrm{d}x} = \\left( \\frac{\\mathrm{d}y}{\\mathrm{d}b}\\frac{\\mathrm{d}b}{\\mathrm{d}a} \\right) \\frac{\\mathrm{d}a}{\\mathrm{d}x}\n\\]\nand \\[\n\\frac{\\mathrm{d}y}{\\mathrm{d}x} =  \\frac{\\mathrm{d}y}{\\mathrm{d}b}\\left(\\frac{\\mathrm{d}b}{\\mathrm{d}a}  \\frac{\\mathrm{d}a}{\\mathrm{d}x} \\right)\n\\]\nThe first mode is called â€œreverse modeâ€ autodiff as the gradient flow is opposite to the data flow. The second mode is called â€œforward modeâ€ autodiff as the order of computation is the same for the gradient computation as for the computation of the function itself.\nBackpropagation is a special case of reverse mode autodiff.\nWhich mode is more efficient depends on whether the input dimension is smaller than the output dimension. If the output dimension is smaller than the input dimension (which is the case for training neural networks) the reverse mode is more efficient as only one application of the reverse mode is needed to compute the gradients.\nThe forward mode, however is of \\(\\mathcal{O(n)}\\), where \\(n\\) is the number of inputs. If the number of inputs is small (or even just one) and the number of outputs is large, e.g.Â \\(\\mathbb{R} \\to \\mathbb{R^m}\\), then the forward mode will be more efficient.\n\n\nSymbolic differentiation vs.Â numerical differentiation vs.Â autodiff\n\nNumerical differentiation involves computing a term like \\(\\frac{\\partial f}{\\partial x_i} \\approx \\frac{f(x+h) - f(x)}{h}\\) for a small \\(h\\). While this is might be relatively easy to implement, but requires \\(\\mathcal{O(n)}\\) evaluations for \\(n\\) gradients, and can be numerically unstable (dividing by small number, subtracting two numbers of almost the same value).\nSymbolic differentation can be performed with systems like Maple, Sympy, or Mathematica. This gives us expressions for the derivatives, which might grow exponentially large (in blind application).\n\n\n\nCode\nimport sympy \nx = sympy.symbols('x')\n\ndef base_function(x): \n    return x**2 +3*x + 4\n\n\n\nAutodiff can easily deal with control flows\n\n\n\nDual numbers\nDual numbers are numbers of the form \\(v+\\dot{v}\\epsilon\\), where \\(\\epsilon\\) has the special property that it is non-zero and \\(\\epsilon^2 = 0\\).\nThey behave as one might expect:\n\\[\n(v+\\dot{v}\\epsilon) + (u + \\dot{u}\\epsilon) = (v + u) + (\\dot{v} + \\dot{u})\\epsilon\n\\]\nand\n\\[\n(v+\\dot{v}\\epsilon)(u+\\dot{u}\\epsilon) = (vu) + (v\\dot{u} + \\dot{u}v)\\epsilon\n\\]\nNow, keep in mind that the Tyalor series of a function $f(x)\n\\[\nf(x) = f(a) + f'(a)(x-a) + \\frac{f''(a)}{2!} (x-a)^2 + \\frac{f'''(a)}{3!} (x-a)^3\n\\]\nNow, if \\(x = a+\\dot{v}\\epsilon\\)\n\\[\nf(a + \\dot{v}\\epsilon) = f(a) + f'(a)(a + \\dot{v}\\epsilon -a) +  \\frac{f''(a)}{2!} (a + \\dot{v}\\epsilon -a)^2 + \\frac{f'''(a)}{3!} (a + \\dot{v}\\epsilon -a)^3\n\\]\nnot that, per definition, all terms with \\(\\epsilon^2\\) or higher powers will vanish. Therefore, we will be left with\n\\[\nf(a + \\dot{v}\\epsilon) = f(a) + f'(a)\\dot{v}\\epsilon\n\\]\nThat is, we can do something like\n\\[\n\\left. \\frac{\\mathrm{d}f}{\\mathrm{d}x}\\right|_{x=a} = \\text{epsilon coefficient}(\\text{dual version}(f)(a+1\\epsilon))\n\\]\nThis means that we directly compute f(x) and the derivative (scaled by \\(\\dot{v}\\)). Thus, we can simulatanously compute the values of functions and derivatives. A naiive implementation might look as follows\n\nimport math \nclass DualNumber:\n    def __init__(self, real, dual):\n        self.real = real  # Real part\n        self.dual = dual  # Dual part (coefficient of epsilon)\n\n    def __repr__(self):\n        return f\"{self.real} + {self.dual}Îµ\"\n    \n    def __add__(self, other):\n        # Addition with another DualNumber or scalar\n        if isinstance(other, DualNumber):\n            return DualNumber(self.real + other.real, self.dual + other.dual)\n        else:\n            return DualNumber(self.real + other, self.dual)\n\n    def __mul__(self, other):\n        # Multiplication with another DualNumber or scalar\n        if isinstance(other, DualNumber):\n            return DualNumber(self.real * other.real, self.real * other.dual + self.dual * other.real)\n        else:\n            return DualNumber(self.real * other, self.dual * other)\n    \n    def __radd__(self, other):\n        return self.__add__(other)\n    \n    def __rmul__(self, other):\n        return self.__mul__(other)\n        \n    def exp(self):\n        # Exponential function\n        exp_real = math.exp(self.real)\n        return DualNumber(exp_real, exp_real * self.dual)\n    \n    def square(self):\n        # Squaring the dual number\n        return DualNumber(self.real**2, 2 * self.real * self.dual)\n\n\ndef complex_function(x):\n    return x.square() * x.exp() + 3*x\n\n# Correcting the differentiation at x = 1\nx = DualNumber(1, 1)\nresult = complex_function(x)\n\nresult.real, result.dual\n\n(5.718281828459045, 11.154845485377136)\n\n\nWhich is correct if we check using WolframAlpha.\n\n\nDifferentiating complex programs\nAutodiff, and thus differentiable programs, are now becoming a first-class citizen in programming languagesâ€”see, for example, the differentiable programming manifesto.\nIn the field of computational materials science a few nice examples include\n\njax-md: Which allows one to differentia through full MD simulations, to do things like the design of kinetic pathways\noptimization of a HÃ¼ckel model implemented in jax\ninverse design of pores"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Kevin's Homepage",
    "section": "",
    "text": "You can also find me on Google Scholar and ORCID."
  },
  {
    "objectID": "scratch/optimism/index.html",
    "href": "scratch/optimism/index.html",
    "title": "When optimism hurts",
    "section": "",
    "text": "A question very close to my heart is whether all the â€œtest scoresâ€ we report in our machine learning studies actually mean anything.\nWhile there are a lot of choices and potential problems just in the fact of deciding to perform a quantiative analysis  and the metrics we choose [see machine learning that matters from Kiri Wagstaff as well as Goodhartâ€™s law and the shortcut rule] a very common pitfall is that we do not have independent test data.see the hierachy of limitations of machine learning from Momin M. Malik on this\nIn the statistical learning community, this has been known as optimism and is conventionally used to show how the training error is not a good estimate of generalization performance.\n-> we can derive optimism and then think of the test dataset as a mix of 100% train, 0% train, or a mix"
  },
  {
    "objectID": "scratch/coding-with-me/index.html",
    "href": "scratch/coding-with-me/index.html",
    "title": "Coding with me",
    "section": "",
    "text": "pre-commit\nruff\nblac$$k\ntyping\nmkdocs\npdm?\nchangelog https://pypi.org/project/git-changelog/\nmakefile\n\nhttps://pawamoy.github.io/copier-pdm/"
  },
  {
    "objectID": "scratch/plotting/index.html",
    "href": "scratch/plotting/index.html",
    "title": "Publication-ready plots with Python",
    "section": "",
    "text": "Over the last decade Iâ€™ve spent a lot of time plotting data. Iâ€™ve tried many different tools and workflows, and Iâ€™ve learned a lot.\nI started with gnuplot, explored pgfplots and large parts of the Python plotting ecosystem.\nMy current setup went back to basics and uses matplotlib and is heavily inspired by the work of Tufte and Jean-Luc Doumont as well as journal requirements."
  },
  {
    "objectID": "scratch/how-much-data/index.html#inductive-biases",
    "href": "scratch/how-much-data/index.html#inductive-biases",
    "title": "How much data do I need?",
    "section": "Inductive biases",
    "text": "Inductive biases"
  },
  {
    "objectID": "scratch/how-much-data/index.html#learning-curves",
    "href": "scratch/how-much-data/index.html#learning-curves",
    "title": "How much data do I need?",
    "section": "Learning curves",
    "text": "Learning curves"
  },
  {
    "objectID": "opensource/opensource.html",
    "href": "opensource/opensource.html",
    "title": " Open Source",
    "section": "",
    "text": "I believe that computational science relies on open code on data and subscribe to the Manifesto put out by Jonathan B. Buckheit and David L. Donoho:"
  },
  {
    "objectID": "opensource/opensource.html#digital-reticular-chemistry-mofworld",
    "href": "opensource/opensource.html#digital-reticular-chemistry-mofworld",
    "title": " Open Source",
    "section": " Digital reticular chemistry â€“ â€œMOFworldâ€",
    "text": "Digital reticular chemistry â€“ â€œMOFworldâ€\nI have been very active in developing tools for â€œdigital reticular chemistryâ€ (see also this article by Yaghi and collaborators), i.e., tools for data-driven science with materials such as metal-organic frameworks (MOFs) and covalent-organic frameworks (COFs).\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nOther References\n\n\n\n\n\n\n\n\n\nmofdscribe\n\n\nAn easy to use tool that accompanies digital reticular chemists on all stages of their work. It provides data sets, more than 40 featurizers, consistent splitting tools to avoid data leakage, as well as tools for evaluating models and comparing them on a leaderboard.\n\n\nPaper\n\n\n\n\n\n\n\nmofchecker\n\n\nThe mofchecker is a tool that allows to check the â€œsanityâ€ of a MOF structure. If implements a range of convenient check, such as checking for missing or overlapping atoms, or unreasonable coordination environment in an easy-to-use interface. Some of the checks also have automatic fixes and are implemented in a graphical interface in an AiiDAlab app.\n\n\nWeb deployment of an earlier version\n\n\n\n\n\n\n\nmoffragmentor\n\n\nThe moffragmentor is a tool that allows to fragment MOF structures into building blocks.\n\n\n\n\n\n\n\n\n\nelement-coder\n\n\nElement coder is a tool that allows to encode elements into a vector spaceâ€”but to also decode them back into the original element. This is useful for machine learning applications where one wants to encode elements into a vector space, but also wants to be able to decode them back into the original element (inverse design).\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "opensource/opensource.html#active-learning",
    "href": "opensource/opensource.html#active-learning",
    "title": " Open Source",
    "section": " Active learning",
    "text": "Active learning\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nOther References\n\n\n\n\n\n\n\n\n\nPyePAL\n\n\nPyePAL implements the e-PAL algorithm for Pareto active learning. It comes with interfaces for a range of machine learning models, including scikit-learn, GPy, and jax. It generalizes to any number of objectives and also supports batches sampling as well as various schedulers for (re)-training the model.\n\n\nPaper\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "opensource/opensource.html#chemical-data-management",
    "href": "opensource/opensource.html#chemical-data-management",
    "title": " Open Source",
    "section": " Chemical Data management",
    "text": "Chemical Data management\nI have been an active contributor to the cheminfo ecosystem. For more details about it, you can give our perspective article a look.\nSome of my contributions are listed below:\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nOther References\n\n\n\n\n\n\n\n\n\nisotherm-analysis\n\n\nisotherm-analysis allows to parse and analyze isotherms. It converts from multiple formats to JCAMP-DX and provides utilities for basic analysis.\n\n\nUsed in our preprint\n\n\n\n\n\n\n\npubchem\n\n\nJavaScript interface to the PubChem API. In the cheminfo ELN, we use this to display safety information.\n\n\n\n\n\n\n\n\n\nxrd-analysis\n\n\nxrd-analysis can convert output files from powder-xray diffraction into JCAMP-DX format and perform analysis (Scherrer equation, â€¦) on the diffractograms.\n\n\nDiscussed in our perspective\n\n\n\n\n\n\n\ntga-analysis\n\n\ntga-analysis provides tools to convert output files from thermogravimetric analysis (TGA) into JCAMP-DX, as well as tools to analyze the data (mass loss analysis).\n\n\n\n\n\n\n\n\n\nbaselines\n\n\nBaselines provides a collection of baseline correction methods.\n\n\n\n\n\n\n\n\n\ncheminfo.github.io\n\n\nI created the web page for the cheminfo organization, which is a collection of FAIR building blocks for chemistry and beyond.\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "teaching/ml/ml_notes.html",
    "href": "teaching/ml/ml_notes.html",
    "title": "Workshop on ML for materials science",
    "section": "",
    "text": "To design new materials, we need to know their properties. There are two main routes to get the properties of a material:\n\nPerform an experiment to measure them\nPerform a simulation to â€œmeasureâ€ them in silico\n\nIn many cases, performing an experiment is time-consuming and, hence, expensive. Also high-fidelity simulations can be very costly. Fidelity expresses the exactness with which a surrogate represents the truth. In the context of ML you might also see the term multi-fidelity, which means that the approach uses multiple approximations with different levels of fidelity, e.g.Â density-functional theory and coupled cluster theory\nTherefore, there is a need for methods that can help us to predict the properties of materials with high fidelity and low cost. In this lecture, we will see that supervised machine learning (ML) is a powerful tool to achieve this goal.\nInterestingly, this tool can be used in many different ways.\n\n\nMachine learning can be used in multiple ways to make high-fidelity predictions of materials less expensive. Note that reducing the cost has been a challenge for chemists and material scientists for a long time. Dirac famously said â€œThe fundamental laws necessary for the mathematical treatment of a large part of physics and the whole of chemistry are thus completely known, and the difficulty lies only in the fact that application of these laws leads to equations that are too complex to be solved. [â€¦] approximate practical methods of applying quantum mechanics should be developed, which can lead to an explanation of the main features of complex atomic systems without too much computationâ€\n\n\n\nMachine learning (green boxes) can be used at multiple places in the material design process.\n\n\n\nReplace expensive evaluation of the potential energy surface \\(U(\\mathbf{X}, \\{\\mathbf{Z}\\})\\): Quantum chemistry as a field is concerned with the prediction of the potential energy surface \\(U(\\mathbf{X}, \\{\\mathbf{Z}\\})\\) of a system of atoms of types \\(\\mathbf{Z}\\) at positions \\(\\mathbf{X}\\). Quantum chemists have developed different approximations to this problem. However, since they are all kinds of functions that map positions of atoms (and atom types, and in some cases electron densities/coordinates) to energies, we can learn those functions with ML.\nNote that once we have done that, we generally still need to perform simulations to extract the properties of interest (e.g.Â as ensemble averages).\nThere are many good review articles about this. For example, see this one by Unke et al. as well as the ones by Deringer et al. and Behler in the same issue of Chemical Reviews.\nDirectly predict the properties of interest Instead of computing the properties of interest using a molecular simulations, we can build models that learn the \\(f(\\mathrm{structure}) \\to \\mathrm{property}\\) mapping directly. The basis for this mapping might be experimental data or high-fidelity computational data.\nAlso about this approach, there are many review articles. I also wrote one, focussing on porous materials.\n\nNote that in the context of using ML for molecular simulations, it can also be used to address sampling problems. We will not cover this in detail in this lecture. For a good introduction, see the seminal paper by Noe and a piece about it by Tuckerman."
  },
  {
    "objectID": "teaching/ml/ml_notes.html#supervised-ml-workflow",
    "href": "teaching/ml/ml_notes.html#supervised-ml-workflow",
    "title": "Workshop on ML for materials science",
    "section": "Supervised ML workflow",
    "text": "Supervised ML workflow\n\n\n\nThe supervised ML workflow.\n\n\nFor the main part of this lecture, we will assume that we use models that consume so-called tabular data, i.e.Â data that is stored in a table (feature matrix \\(\\mathbf{X}\\) and target/label vector/matrix \\(\\mathbf{Y}\\)), where each row corresponds to a material and each of the \\(p\\) columns corresponds to a so-called feature. We wil later see that this is not the only way to use ML for materials science, but it is the most common one. We will also explore in more detail how we obtain the features.\nWe will use some data \\(\\mathcal{D} = \\{(\\mathbf{x}_i, y_i)\\}_{i=1}^N\\) to train a model \\(f(\\mathbf{x}) \\to y\\) that can predict the target \\(y\\) for a new structure described with the feature vector \\(\\mathbf{x}^*\\)."
  },
  {
    "objectID": "teaching/ml/ml_notes.html#feeding-structures-into-models",
    "href": "teaching/ml/ml_notes.html#feeding-structures-into-models",
    "title": "Workshop on ML for materials science",
    "section": "Feeding structures into models",
    "text": "Feeding structures into models\n\nIncorporating symmetries/invariances/equivariances\n\nLearning a very simple force field\nTo understand what it takes to feed structures into ML models, let us try to build a very simple force field. To make things simple and fast, we will just attempt to predict the energies of different conformers of the same molecule.\nWe will create some data using RDkit and then use scikit-learn to train a model.\n\nGenerating data\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom pymatviz.parity import density_scatter_with_hist\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem, PyMol\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nimport matplotx\nplt.style.use(['science', 'nature', matplotx.styles.dufte])\n\ndef gen_conformers(mol, numConfs=10_000, maxAttempts=1000, \n    pruneRmsThresh=0.2, useExpTorsionAnglePrefs=True, \n    useBasicKnowledge=True, enforceChirality=True):\n    \"\"\"Use RDkit to generate conformers for a molecule.\"\"\"\n    ids = AllChem.EmbedMultipleConfs(mol, numConfs=numConfs, maxAttempts=maxAttempts, pruneRmsThresh=pruneRmsThresh, useExpTorsionAnglePrefs=useExpTorsionAnglePrefs, useBasicKnowledge=useBasicKnowledge, enforceChirality=enforceChirality, numThreads=0)\n    return list(ids)\n\ndef calc_energy(mol, conformer_id, iterations=0):\n    \"\"\"Calculate the energy of a conformer using the Merck Molecular Force Field.\"\"\"\n    ff = AllChem.MMFFGetMoleculeForceField(mol, AllChem.MMFFGetMoleculeProperties(mol), confId=conformer_id)\n    ff.Initialize()\n    ff.CalcEnergy()\n    results = {}\n    if iterations > 0:\n        results[\"converged\"] = ff.Minimize(maxIts=iterations)\n    results[\"energy_abs\"] = ff.CalcEnergy()\n    return results\n\n# create a molecule\nmol = Chem.AddHs(Chem.MolFromSmiles('CC(CCC)CC(C)(CCCC)O'))\n\n# visualize some conformers using PyMol\nconformer_ids = gen_conformers(mol)\nv= PyMol.MolViewer()\nv.DeleteAll()\nfor cid in conformer_ids[:50]: \n    v.ShowMol(mol,confId=cid,name='Conf-%d'%cid,showOnly=False)\nv.server.do('set grid_mode, on')\nv.server.do('ray')\nv.GetPNG()\n\n\n\n\nFor those conformers, we can now retrieve the positions and energies and save them in a pandas dataframe.\n\n# make column names\ncoordinate_names = sum([[f'x_{n}',f'y_{n}', f'z_{n}'] for n in range(mol.GetNumAtoms())], []) \n\n# make a dataframe\ndata = []\nfor conformer_id in conformer_ids:\n    energy = calc_energy(mol, conformer_id)['energy_abs']\n    positions = mol.GetConformer(conformer_id).GetPositions().flatten()\n    position_dict = dict(zip(coordinate_names, positions))\n    position_dict['energy'] = energy\n    data.append(position_dict)\ndata = pd.DataFrame(data).sample(len(data))\ndata\n\n\n\n\n\n  \n    \n      \n      x_0\n      y_0\n      z_0\n      x_1\n      y_1\n      z_1\n      x_2\n      y_2\n      z_2\n      x_3\n      ...\n      x_36\n      y_36\n      z_36\n      x_37\n      y_37\n      z_37\n      x_38\n      y_38\n      z_38\n      energy\n    \n  \n  \n    \n      2043\n      -1.078591\n      0.818283\n      1.240628\n      -0.800294\n      0.502684\n      -0.201929\n      -1.954519\n      1.026058\n      -1.025512\n      -3.273669\n      ...\n      3.251420\n      2.714797\n      0.788806\n      3.367359\n      2.219022\n      -0.991762\n      0.989111\n      -3.501398\n      0.263898\n      57.642061\n    \n    \n      708\n      2.297451\n      -0.588703\n      1.198600\n      1.849392\n      -0.812041\n      -0.206686\n      2.744403\n      -0.182895\n      -1.240594\n      2.906312\n      ...\n      -4.716954\n      2.169116\n      -1.544502\n      -5.228039\n      1.863652\n      0.124533\n      0.114421\n      -2.761600\n      -0.960946\n      54.244578\n    \n    \n      408\n      1.163540\n      -1.312797\n      -2.566840\n      1.551876\n      -0.236862\n      -1.563855\n      2.214690\n      -0.885194\n      -0.416510\n      2.675456\n      ...\n      -4.168519\n      -0.135408\n      2.800937\n      -3.585246\n      -1.333950\n      3.969698\n      -1.691907\n      0.246868\n      -2.597852\n      52.567947\n    \n    \n      1002\n      -1.867094\n      -1.693097\n      -1.332886\n      -1.541937\n      -0.278548\n      -0.948931\n      -2.886193\n      0.397350\n      -0.687940\n      -2.772851\n      ...\n      4.794642\n      1.574557\n      0.373096\n      3.065221\n      1.557351\n      0.781498\n      0.572776\n      -0.734201\n      2.068011\n      54.796651\n    \n    \n      1321\n      2.928589\n      -1.644500\n      -0.316096\n      1.745386\n      -0.908216\n      0.368037\n      1.712225\n      0.465713\n      -0.229357\n      3.044419\n      ...\n      -2.063003\n      2.004943\n      -1.485612\n      -3.559160\n      2.933577\n      -1.076262\n      -1.837432\n      -2.695152\n      -0.441605\n      48.166088\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1116\n      -3.142345\n      -1.189532\n      -0.401893\n      -1.930097\n      -0.626832\n      0.346319\n      -1.753804\n      0.824601\n      0.262187\n      -2.876675\n      ...\n      4.956526\n      0.643734\n      1.010794\n      4.919351\n      2.416299\n      0.814133\n      0.552486\n      -1.910775\n      2.199388\n      70.883781\n    \n    \n      1955\n      1.685931\n      -2.472720\n      -0.940277\n      1.534224\n      -1.356805\n      0.238021\n      2.715622\n      -0.563858\n      -0.031399\n      3.177957\n      ...\n      -5.025281\n      0.698320\n      0.708392\n      -3.869999\n      1.960012\n      0.214193\n      -1.032830\n      0.387742\n      2.688491\n      81.512316\n    \n    \n      842\n      -1.142410\n      0.366678\n      -1.588368\n      -1.329860\n      0.783292\n      -0.150924\n      -2.783483\n      1.104390\n      0.152162\n      -3.683336\n      ...\n      5.412591\n      1.012171\n      -0.679850\n      5.268181\n      -0.551458\n      0.257663\n      0.956310\n      -2.102239\n      -0.739920\n      44.487110\n    \n    \n      22\n      2.782766\n      -0.786184\n      -1.322582\n      1.828757\n      -0.846233\n      -0.084366\n      2.433197\n      -0.189490\n      1.062991\n      2.823427\n      ...\n      -2.935750\n      1.666981\n      -0.663128\n      -4.666748\n      1.184414\n      -1.000579\n      -0.265753\n      -2.606498\n      0.368280\n      76.366987\n    \n    \n      314\n      -1.989624\n      1.571328\n      0.448798\n      -1.562195\n      0.547476\n      -0.531285\n      -2.366938\n      -0.678900\n      -0.674343\n      -3.779642\n      ...\n      4.722953\n      2.322387\n      -0.370448\n      6.072408\n      1.184723\n      -0.149746\n      -0.124138\n      0.430200\n      2.444614\n      54.955516\n    \n  \n\n3172 rows Ã— 118 columns\n\n\n\nGiven this data, we can build a model. We will use a gradient boosting regressor from scikit-learn. We will also split the data into a training and a test set. In later sections, we will see why this is important. But for now, let us us just appreciate that a test setâ€”conformers we did not train onâ€”will give us a measure of how well our model will perform on new, unseen, conformers.\n\npositions = data[coordinate_names] # X\nenergies = data['energy'] # y\n\n# split into training and test set\ntrain_points = 3000\ntrain_positions = positions[:train_points]\ntest_positions = positions[train_points:]\ntrain_energies = energies[:train_points]\ntest_energies = energies[train_points:]\n\n# train a model\nfrom sklearn.ensemble import HistGradientBoostingRegressor\nmodel = HistGradientBoostingRegressor()\nmodel.fit(train_positions, train_energies)\n\nHistGradientBoostingRegressor()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.HistGradientBoostingRegressorHistGradientBoostingRegressor()\n\n\nOnce we have trained a model, we can use it to predict the energies of new conformers. Letâ€™s first see how well it does on the data it was trained on.\n\ntrain_predictions = model.predict(train_positions)\n\n\ndensity_scatter_with_hist(train_energies.values, train_predictions, xlabel='True energy', ylabel='Predicted energy')\n\n<AxesSubplot: xlabel='True energy', ylabel='Predicted energy'>\n\n\n\n\n\nThis looks pretty good. But how well does it do on new conformers? Letâ€™s see.\n\ntest_predictions = model.predict(test_positions)\n\ndensity_scatter_with_hist(test_energies.values, test_predictions, xlabel='True energy', ylabel='Predicted energy')\n\n<AxesSubplot: xlabel='True energy', ylabel='Predicted energy'>\n\n\n\n\n\nFrom physics we know that (without external field) the energy of a molecule does not depend on where in space it is. That is, if we translate a molecule along \\([1, 1, 1]\\), the energy should not change.\n\n# translate the molecule along [1, 1, 1]\ntranslated_positions = train_positions + 1\ntranslated_predictions = model.predict(translated_positions)\ndensity_scatter_with_hist(train_energies.values, translated_predictions)\n\n<AxesSubplot: xlabel='Actual', ylabel='Predicted'>\n\n\n\n\n\nThis is not what we expect. Our model shows completly unphysical behavior and predicts a different energy for the same conformers in different positions in space.\nTo fix this, and related problems, we need to use a more elaborate approach to building a model.\n\n\n\nMmaking predictions invariant/equivariant to transformations\nInvariance and equivariance are terms that have become very relevant in ML. It is always important to mention with respect to what operation something is invariant and equivariant; if people donâ€™t mention this they often refer to the symmetry operations of the Euclidean group which comprises all translations, rotations, and reflection. Invariant means that the property of interest does not change under those operations. Equivariant means that it changes in the same way. The energy, for example, is invariant and the forces are equivariant.\n\nWhat are symmetries we would like to respect?\nBefore we can talk about how to build a model that respects symmetries, we need to know what symmetries we would like to respect.\nIn the case of molecules, we would like to respect the following symmetries:\n\ntranslation: that is, if we move a molecule along a vector, the energy should not change (see above)\nrotation: that is, if we rotate a molecule, the energy should not change\npermutation of atoms: that is the order with which we put the atoms in the model does not matter\n\nFor crystals, we additionally need to respect periodicity. That is, for intensive properties, there should be no difference between using a unit cell or a super cell of that unit cell as input for a model.\nBroadly speaking, there are three different ways to build models that respect symmetries.\n\nData augmentation: This is the most straightforward approach. We can generate new data points by applying the symmetries to the existing data points. For example, we can generate new conformers by rotating the existing conformers. This approach is very simple to implement, but it can be very expensive. For example, if we want to generate new conformers by rotating the existing conformers, we need to generate a new conformer for every rotation. This approach is often used for computer vision pipelines in which you might want to detect a cat in an image independent of the orientation. In this case, you can generate new images by rotating the existing images.\nFeatures that are invariant/equivariant : This approach is more sophisticated. We can build features that are invariant/equivariant to the symmetries we want to respect. For example, we can build features that are invariant to rotation. In the case of force field such features are bond lengths and angles. This is approach is widely used in ML for chemistry and materials science.\nModels that are invariant/equivariant: Alternatively, one can build special models that can consume point clouds as inputs and are equivariant to the symmetries we want to respect. We will not discuss this in detail, but you can find starting points in this perspective by Tess Smidt.\n\n\n\nInvariant/equivariant features\n\nSymmetry functions\n\n\nFingerprints\n\n\nCorrelation functions\n\n\nSymmetry functions\n\n\nCheaper computations"
  },
  {
    "objectID": "teaching/ml/ml_notes.html#training-a-model",
    "href": "teaching/ml/ml_notes.html#training-a-model",
    "title": "Workshop on ML for materials science",
    "section": "Training a model",
    "text": "Training a model\n\nHow to know if a model is good?\nBefore we can proceed to building models, we need to estabilsh a way to measure how good a model is.\nInterestingly, this is not as trivial as it may sound. To realize this, it is useful to formally write down what we mean by a good model.\n\nEmpirical risk minimization\nLetâ€™s assume we have some input space \\(\\mathcal{X}\\) and some output space \\(\\mathcal{Y}\\). We can think of \\(\\mathcal{X}\\) as the space of all possible inputs and \\(\\mathcal{Y}\\) as the space of all possible outputs. For example, \\(\\mathcal{X}\\) could be the space of all possible molecules and \\(\\mathcal{Y}\\) could be the space of all possible energies. We want to learn a function \\(f: \\mathcal{X} \\rightarrow \\mathcal{Y}\\) that maps inputs to outputs. We can think of \\(f\\) as a model that we want to train.\nTo build this models we have samples of the joint distribution \\(p(x, y)\\), where \\(x\\) is an input and \\(y\\) is the corresponding output. We can think of this as a set of data points \\(\\{(x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)\\}\\).\nIf we now define a loss function \\(L\\) we can compute the risk, which is the expected value of the loss function:\n\\[\nR(h)={\\mathbf  {E}}[L(f(x),y)]=\\int L(f(x),y)\\,dP(x,y).\n\\]\nour goal is to find a model \\(f\\) that minimizes the risk:\n\\[\n{\\displaystyle h^{*}={\\underset {h\\in {\\mathcal {H}}}{\\operatorname {arg\\,min} }}\\,{R(h)}.}\n\\]\nIn practice we cannot compute this. The reason is that we do not have access to the joint distribution \\(p(x, y)\\), but only to a finite set of samples \\(\\{(x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)\\}\\).\n\n\n\nLinear regression\nimport jax.numpy as jnp\n\ndef linear_regression(x, w, b):\n    return jnp.dot(x, w) + b\ndef loss(w, b):\n    prediction = linear_regression(x, w, b)\n    return jnp.mean((prediction - y) ** 2)\ndef init_params(num_feat):\n    return np.random.normal(size=(num_feat,)), 0.0\nloss_grad = jax.grad(loss, argnums=(0, 1))\nlearning_rate = 1e-6\nnum_epochs = 1000"
  },
  {
    "objectID": "teaching/ml/ml_notes.html#bias-variance-trade-off",
    "href": "teaching/ml/ml_notes.html#bias-variance-trade-off",
    "title": "Workshop on ML for materials science",
    "section": "Bias-variance trade-off",
    "text": "Bias-variance trade-off"
  },
  {
    "objectID": "teaching/ml/ml_notes.html#hyperparameters",
    "href": "teaching/ml/ml_notes.html#hyperparameters",
    "title": "Workshop on ML for materials science",
    "section": "Hyperparameters",
    "text": "Hyperparameters"
  },
  {
    "objectID": "teaching/ml/ml_notes.html#kernel-trick",
    "href": "teaching/ml/ml_notes.html#kernel-trick",
    "title": "Workshop on ML for materials science",
    "section": "Kernel trick",
    "text": "Kernel trick\n\n\n\nKernel-based machine learning can be thought of expressing the property of interest via an expansion in a basis spanned by the structures in the training set. Figure taken from M. A. Caro,Â ArkhimedesÂ 2018,Â 3,Â 21."
  },
  {
    "objectID": "teaching/ml/ml_notes.html#feature-importance",
    "href": "teaching/ml/ml_notes.html#feature-importance",
    "title": "Workshop on ML for materials science",
    "section": "Feature importance",
    "text": "Feature importance\n\nPermutation feature importance"
  },
  {
    "objectID": "teaching/ml/ml_notes.html#feature-selection",
    "href": "teaching/ml/ml_notes.html#feature-selection",
    "title": "Workshop on ML for materials science",
    "section": "Feature selection",
    "text": "Feature selection\n\nCurse of dimensionality\nFor understanding the curse of dimensionality, it is useful to consider a very simple ML model, the \\(k\\)-nearest neighbors model. In this model, we have a set of training points \\(\\{(x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)\\}\\), where \\(x_i\\) is a vector of features and \\(y_i\\) is the corresponding label. To make a prediction, we compute the distance between the input and all training points and return the mode of the labels of the \\(k\\) closest training points.\nClearly, in this algorithm it is important to find the nearest neighbor. In general, this is important in many algorithms, for instance also in kernel-based learning.\nLetâ€™s now ask ourself what part of the space we need to find the nearest neighbors.\n\nFor this, letâ€™s start considering a unit cube \\([0,1]^d\\) and \\(n\\) data points \\(x_i\\) sampled uniformly from this cube.\nThe smallest hypercube that contains \\(k\\) out of the \\(n\\) points has the following edge length\n\\[\nl^d = \\frac{k}{n} \\quad \\Rightarrow \\quad l = \\left(\\frac{k}{n}\\right)^{1/d}\n\\]\nIf we plot this for different values of \\(d\\) we get the following plot:\n\nimport matplotlib.pyplot as plt\nimport numpy as np \n\ndef length(d, k=5, n=10_000):\n    return (k/n)**(1/d)\n\nd = np.arange(1, 1000)\n\nplt.plot(d, length(d))\nplt.xlabel('numbr of dimensions')\nplt.ylabel('length of hypercube that contains k neighbors')\n\nText(0, 0.5, 'length of hypercube that contains k neighbors')\n\n\n\n\n\nClearly, for large \\(d\\) the length approaches 1â€”which means that all points are now almost equally far apart and comparing distances no longer makes much sense.\nWe can also check this by performing a simulation: Generating random \\(d\\) dimensional points and computing the distance between them. We can then plot the distribution of distances.\n\nfrom scipy.spatial import distance_matrix\ndimensions = [2, 5, 10, 100, 10_000]\nnum_points = 1000\n\nfig, axes = plt.subplots(1, len(dimensions), sharey='all')\n\ndef get_distances(d, num_points):\n    points = np.random.uniform(size=(num_points, d))\n    distances = distance_matrix(points, points)\n    return np.array(distances).flatten()\n\nfor d, ax in zip(dimensions, axes):\n    distances = get_distances(d, num_points)\n    ax.hist(distances, bins=20)\n    ax.set_title(f'd={d} \\n cv={distances.std()/distances.mean():.2f}')\n\n\n\n\nClearly, for large \\(d\\) the distances are almost the same (the histograms are much more peaked). We can also see this in terms of the coefficient of variation (cv), which is the standard deviation divided by the mean. For large \\(d\\) the cv is very small, which means that the distances are very similar.\n\n\nFeature selection approaches"
  },
  {
    "objectID": "teaching/ml/ml_notes.html#feature-projection",
    "href": "teaching/ml/ml_notes.html#feature-projection",
    "title": "Workshop on ML for materials science",
    "section": "Feature projection",
    "text": "Feature projection\n\nPrincipal component analysis\n\n\nt-distributed stochastic neighbor embedding"
  },
  {
    "objectID": "teaching/ml/ml_notes.html#feature-learning",
    "href": "teaching/ml/ml_notes.html#feature-learning",
    "title": "Workshop on ML for materials science",
    "section": "Feature learning",
    "text": "Feature learning"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Kevin's Homepage",
    "section": "",
    "text": "In case you canâ€™t see the embedded document, you can download it here."
  },
  {
    "objectID": "bio.html",
    "href": "bio.html",
    "title": "Bio",
    "section": "",
    "text": "Kevin Jablonka obtained his bachelorâ€™s degree in chemistry at TU Munich. He joined EPFL for his masterâ€™s studies (and an extended study degree in applied machine learning), after which he joined Berend Smitâ€™s group for a Ph.D.Â He now leads a research group at the Helmholtz Institute for Polymers in Energy Applications of the University of Jena and the Helmholtz Center Berlin. Kevinâ€™s research interests are in the digitization of chemistry. For this, he has been contributing to the cheminfo electronic lab notebook ecosystem. He also developed a toolbox for digital reticular chemistry. Using tools from this toolbox, he addressed questions from the atom to the pilot-plant scale. Kevin is also interested in using large language models in chemistry and co-leads the ChemNLP project (with support from OpenBioML.org and Stability.AI).\n\nMore\nIf you need more info, see my CV. If you need a headshot, you can use this one: portrait.jpg."
  }
]